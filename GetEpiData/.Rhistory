if_else(TwoWeekIncidence<=10 & Slope3DAverage>=-0.1 & Slope3DAverage<0.1,"Low Incidence Plateau","No classification"))))))
UpdatedCountryDataset<-UpdatedCountryDataset %>%
mutate(EpidemicStatusCurveDailyRate=if_else(TwoWeekIncidence<10 & SlopeDailyRate>=0.1,"Low Incidence Growth",
if_else(TwoWeekIncidence>10 & SlopeDailyRate>=0.1,"Elevated Incidence Growth",
if_else(TwoWeekIncidence>10 & SlopeDailyRate>=-0.1 & SlopeDailyRate <0.1,"Elevated Incidence Plateau",
if_else(SlopeDailyRate<=-0.1,"Sustained Decline",
if_else(TwoWeekIncidence<=10 & SlopeDailyRate>=-0.1 & SlopeDailyRate<0.1,"Low Incidence Plateau","No classification"))))))
plot3Days<-ggplot(UpdatedCountryDataset)+
# geom_bar(aes(x=DateReport1,y=DailyRateCases,fill=SlopeClassification),stat="identity")+
# scale_fill_manual(breaks = c("Greater increase","Moderate increase","Plateau","Moderate decline","Greater decline"),
#                   values=c("#E45549","#FDBC6D","#FFFFBF","#BCE4A0","#4CA5B1"))+
geom_bar(aes(x=DateReport1,y=ThreeDaysAverage,fill=EpidemicStatusCurve3DAverage),stat="identity")+
scale_fill_manual("Epidemic Status Curve",breaks = c("Elevated Incidence Growth","Low Incidence Growth","Elevated Incidence Plateau","Low Incidence Plateau","Sustained Decline"),
values=c("#E45549","#FDBC6D","#FFFFBF","#BCE4A0","#4CA5B1"))+
#geom_line(aes(x=DateReport1,y=DailyRateCases),size=1,color="black",linetype=2,alpha=0.7)+
#geom_line(aes(x=DateReport1,y=ThreeDaysAverage),size=1,color="black",alpha=0.7)+
geom_line(aes(x=DateReport1,y=SplineDailyRate),color="black",linetype="dotted",size=0.5)+
geom_line(aes(x=DateReport1,y=Spline3DAverage),color="black",size=0.5)+
#geom_line(aes(x=DateReport1,y=Slope),linetype=2,color="#06304A")+
labs(x="Reporting date",y="Daily rate cases \n (Three Days Average)")+
ggtitle(paste0("spar=",smoothparameter))+
ChartTheme+theme(legend.title = element_text(size=8,face="bold"),legend.text = element_text(size=8),legend.key.size=unit(0.2,"cm"))
plotDailyRate<-ggplot(UpdatedCountryDataset)+
# geom_bar(aes(x=DateReport1,y=DailyRateCases,fill=SlopeClassification),stat="identity")+
# scale_fill_manual(breaks = c("Greater increase","Moderate increase","Plateau","Moderate decline","Greater decline"),
#                   values=c("#E45549","#FDBC6D","#FFFFBF","#BCE4A0","#4CA5B1"))+
geom_bar(aes(x=DateReport1,y=ThreeDaysAverage,fill=EpidemicStatusCurveDailyRate),stat="identity")+
scale_fill_manual("Epidemic Status Curve",breaks = c("Elevated Incidence Growth","Low Incidence Growth","Elevated Incidence Plateau","Low Incidence Plateau","Sustained Decline"),
values=c("#E45549","#FDBC6D","#FFFFBF","#BCE4A0","#4CA5B1"))+
#geom_line(aes(x=DateReport1,y=DailyRateCases),size=1,color="black",linetype=2,alpha=0.7)+
#geom_line(aes(x=DateReport1,y=ThreeDaysAverage),size=1,color="black",alpha=0.7)+
geom_line(aes(x=DateReport1,y=Spline3DAverage),color="black",linetype="dotted",size=0.5)+
geom_line(aes(x=DateReport1,y=SplineDailyRate),color="black",size=0.5)+
#geom_line(aes(x=DateReport1,y=Slope),linetype=2,color="#06304A")+
labs(x="Reporting date",y="Rate cases")+
ggtitle(paste0("spar=",smoothparameter))+
ChartTheme+theme(legend.title = element_text(size=8,face="bold"),legend.text = element_text(size=8),legend.key.size=unit(0.2,"cm"))
return(list(plot3Days=plot3Days,plotDailyRate=plotDailyRate,UpdatedCountryDataset=UpdatedCountryDataset))
}
#####
########## Viz 1
spar<-c(0.25,0.5,0.75,1)
ListCountries<-unique((MainDataset %>%
filter(ADM0NAME=="Turkey" | ADM0NAME=="Ukraine" | ADM0NAME=='United Kingdom' | ADM0NAME=='Uzbekistan' | ADM0NAME=='Kosovo'))$ADM0NAME)
for (Country in ListCountries) {
Chart_1<-(CDCMethodology(Country,spar[1]))$plotDailyRate
Chart_2<-(CDCMethodology(Country,spar[2]))$plotDailyRate
Chart_3<-(CDCMethodology(Country,spar[3]))$plotDailyRate
Chart_4<-(CDCMethodology(Country,spar[4]))$plotDailyRate
Chart_5<-(CDCMethodology(Country,spar[1]))$plot3Days
Chart_6<-(CDCMethodology(Country,spar[2]))$plot3Days
Chart_7<-(CDCMethodology(Country,spar[3]))$plot3Days
Chart_8<-(CDCMethodology(Country,spar[4]))$plot3Days
Col1<-grid.arrange(Chart_1,Chart_2,Chart_3,Chart_4,ncol=1) %>% annotate_figure(top="Based on daily incidence")
Col2<-grid.arrange(Chart_5,Chart_6,Chart_7,Chart_8,ncol=1) %>% annotate_figure(top="Based on 3days average daily incidence")
GridPlot<-grid.arrange(Col1,Col2,ncol=2) %>%
ggsave(filename=paste0(folder,"/Output/",CurrentDate,"/InfluenceSmoothing/",Country,"_InfluenceSpline.jpg"),width = 14, height = 8)
print(Country)}
########## Viz 2
spar<-c(0.5,0.75)
ListCountries<-ProfilesToGenerate$CountryOfInterest
for (Country in ListCountries) {
Chart_1<-(CDCMethodology(Country,spar[1]))$plotDailyRate
Table_1<-(CDCMethodology(Country,spar[1]))$UpdatedCountryDataset %>% select(DateReport1,NewCases,TwoWeekIncidence,SlopeDailyRate) %>% ggtexttable(rows=NULL,theme = ttheme(base_size = 8))
Chart_2<-(CDCMethodology(Country,spar[2]))$plotDailyRate
Table_2<-(CDCMethodology(Country,spar[2]))$UpdatedCountryDataset %>% select(DateReport1,NewCases,TwoWeekIncidence,SlopeDailyRate) %>% ggtexttable(rows=NULL,theme = ttheme(base_size = 8))
Chart_3<-(CDCMethodology(Country,spar[1]))$plot3Days
Table_3<-(CDCMethodology(Country,spar[1]))$UpdatedCountryDataset %>% select(DateReport1,NewCases,TwoWeekIncidence,Slope3DAverage) %>% ggtexttable(rows=NULL,theme = ttheme(base_size = 8))
Chart_4<-(CDCMethodology(Country,spar[2]))$plot3Days
Table_4<-(CDCMethodology(Country,spar[2]))$UpdatedCountryDataset %>% select(DateReport1,NewCases,TwoWeekIncidence,Slope3DAverage) %>% ggtexttable(rows=NULL,theme = ttheme(base_size = 8))
Col1<-grid.arrange(Chart_1,Table_1,Chart_2,Table_2,ncol=1) %>% annotate_figure(top="Based on daily incidence")
Col2<-grid.arrange(Chart_3,Table_3,Chart_4,Table_4,ncol=1) %>% annotate_figure(top="Based on 3days average daily incidence")
GridPlot<-grid.arrange(Col1,Col2,ncol=2) %>%
ggsave(filename=paste0(folder,"/Output/",CurrentDate,"/InfluenceSmoothing/",Country,"_InfluenceSplineAndTables.jpg"),width = 14, height = 50,limitsize = FALSE)
print(Country)}
ListCountries<-ProfilesToGenerate$CountryOfInterest
spar<-c(0.5,0.75)
ListCountries<-ProfilesToGenerate$CountryOfInterest
for (Country in ListCountries) {
Chart_1<-(CDCMethodology(Country,spar[1]))$plotDailyRate
Table_1<-(CDCMethodology(Country,spar[1]))$UpdatedCountryDataset %>% select(DateReport1,NewCases,TwoWeekIncidence,SlopeDailyRate) %>% ggtexttable(rows=NULL,theme = ttheme(base_size = 8))
Chart_2<-(CDCMethodology(Country,spar[2]))$plotDailyRate
Table_2<-(CDCMethodology(Country,spar[2]))$UpdatedCountryDataset %>% select(DateReport1,NewCases,TwoWeekIncidence,SlopeDailyRate) %>% ggtexttable(rows=NULL,theme = ttheme(base_size = 8))
Chart_3<-(CDCMethodology(Country,spar[1]))$plot3Days
Table_3<-(CDCMethodology(Country,spar[1]))$UpdatedCountryDataset %>% select(DateReport1,NewCases,TwoWeekIncidence,Slope3DAverage) %>% ggtexttable(rows=NULL,theme = ttheme(base_size = 8))
Chart_4<-(CDCMethodology(Country,spar[2]))$plot3Days
Table_4<-(CDCMethodology(Country,spar[2]))$UpdatedCountryDataset %>% select(DateReport1,NewCases,TwoWeekIncidence,Slope3DAverage) %>% ggtexttable(rows=NULL,theme = ttheme(base_size = 8))
Col1<-grid.arrange(Chart_1,Table_1,Chart_2,Table_2,ncol=1) %>% annotate_figure(top="Based on daily incidence")
Col2<-grid.arrange(Chart_3,Table_3,Chart_4,Table_4,ncol=1) %>% annotate_figure(top="Based on 3days average daily incidence")
GridPlot<-grid.arrange(Col1,Col2,ncol=2) %>%
ggsave(filename=paste0(folder,"/Output/",CurrentDate,"/InfluenceSmoothing/",Country,"_InfluenceSplineAndTables.jpg"),width = 14, height = 50,limitsize = FALSE)
print(Country)}
spar<-c(0.5,0.75)
ListCountries<-ProfilesToGenerate$CountryOfInterest
for (Country in ListCountries) {
Chart_1<-(CDCMethodology(Country,spar[1]))$plotDailyRate
Table_1<-(CDCMethodology(Country,spar[1]))$UpdatedCountryDataset %>% select(DateReport1,NewCases,TwoWeekIncidence,SlopeDailyRate) %>% ggtexttable(rows=NULL,theme = ttheme(base_size = 8))
Chart_2<-(CDCMethodology(Country,spar[2]))$plotDailyRate
Table_2<-(CDCMethodology(Country,spar[2]))$UpdatedCountryDataset %>% select(DateReport1,NewCases,TwoWeekIncidence,SlopeDailyRate) %>% ggtexttable(rows=NULL,theme = ttheme(base_size = 8))
Chart_3<-(CDCMethodology(Country,spar[1]))$plot3Days
Table_3<-(CDCMethodology(Country,spar[1]))$UpdatedCountryDataset %>% select(DateReport1,NewCases,TwoWeekIncidence,Slope3DAverage) %>% ggtexttable(rows=NULL,theme = ttheme(base_size = 8))
Chart_4<-(CDCMethodology(Country,spar[2]))$plot3Days
Table_4<-(CDCMethodology(Country,spar[2]))$UpdatedCountryDataset %>% select(DateReport1,NewCases,TwoWeekIncidence,Slope3DAverage) %>% ggtexttable(rows=NULL,theme = ttheme(base_size = 8))
Col1<-grid.arrange(Chart_1,Table_1,Chart_2,Table_2,ncol=1) %>% annotate_figure(top="Based on daily incidence")
Col2<-grid.arrange(Chart_3,Table_3,Chart_4,Table_4,ncol=1) %>% annotate_figure(top="Based on 3days average daily incidence")
GridPlot<-grid.arrange(Col1,Col2,ncol=2) %>%
ggsave(filename=paste0(folder,"/Output/",CurrentDate,"/InfluenceSmoothing/",Country,"_InfluenceSplineAndTables.jpg"),width = 14, height = 30,limitsize = FALSE)
print(Country)}
########## Viz 2
spar<-c(0.5,0.75)
ListCountries<-ProfilesToGenerate$CountryOfInterest
for (Country in ListCountries) {
Chart_1<-(CDCMethodology(Country,spar[1]))$plotDailyRate
Table_1<-(CDCMethodology(Country,spar[1]))$UpdatedCountryDataset %>% select(DateReport1,NewCases,TwoWeekIncidence,SlopeDailyRate) %>% ggtexttable(rows=NULL,theme = ttheme(base_size = 8))
Chart_2<-(CDCMethodology(Country,spar[2]))$plotDailyRate
Table_2<-(CDCMethodology(Country,spar[2]))$UpdatedCountryDataset %>% select(DateReport1,NewCases,TwoWeekIncidence,SlopeDailyRate) %>% ggtexttable(rows=NULL,theme = ttheme(base_size = 8))
Chart_3<-(CDCMethodology(Country,spar[1]))$plot3Days
Table_3<-(CDCMethodology(Country,spar[1]))$UpdatedCountryDataset %>% select(DateReport1,NewCases,TwoWeekIncidence,Slope3DAverage) %>% ggtexttable(rows=NULL,theme = ttheme(base_size = 8))
Chart_4<-(CDCMethodology(Country,spar[2]))$plot3Days
Table_4<-(CDCMethodology(Country,spar[2]))$UpdatedCountryDataset %>% select(DateReport1,NewCases,TwoWeekIncidence,Slope3DAverage) %>% ggtexttable(rows=NULL,theme = ttheme(base_size = 8))
Col1<-grid.arrange(Chart_1,Table_1,Chart_2,Table_2,ncol=1) %>% annotate_figure(top="Based on daily incidence")
Col2<-grid.arrange(Chart_3,Table_3,Chart_4,Table_4,ncol=1) %>% annotate_figure(top="Based on 3days average daily incidence")
GridPlot<-grid.arrange(Col1,Col2,ncol=2) %>%
ggsave(filename=paste0(folder,"/Output/",CurrentDate,"/InfluenceSmoothing/",Country,"_InfluenceSplineAndTables.jpg"),width = 14, height = 8)
print(Country)}
spar<-c(0.5,0.75)
ListCountries<-ProfilesToGenerate$CountryOfInterest
for (Country in ListCountries) {
Chart_1<-(CDCMethodology(Country,spar[1]))$plotDailyRate
Table_1<-(CDCMethodology(Country,spar[1]))$UpdatedCountryDataset %>% select(DateReport1,NewCases,TwoWeekIncidence,SlopeDailyRate) %>% ggtexttable(rows=NULL,theme = ttheme(base_size = 8))
Chart_2<-(CDCMethodology(Country,spar[2]))$plotDailyRate
Table_2<-(CDCMethodology(Country,spar[2]))$UpdatedCountryDataset %>% select(DateReport1,NewCases,TwoWeekIncidence,SlopeDailyRate) %>% ggtexttable(rows=NULL,theme = ttheme(base_size = 8))
Chart_3<-(CDCMethodology(Country,spar[1]))$plot3Days
Table_3<-(CDCMethodology(Country,spar[1]))$UpdatedCountryDataset %>% select(DateReport1,NewCases,TwoWeekIncidence,Slope3DAverage) %>% ggtexttable(rows=NULL,theme = ttheme(base_size = 8))
Chart_4<-(CDCMethodology(Country,spar[2]))$plot3Days
Table_4<-(CDCMethodology(Country,spar[2]))$UpdatedCountryDataset %>% select(DateReport1,NewCases,TwoWeekIncidence,Slope3DAverage) %>% ggtexttable(rows=NULL,theme = ttheme(base_size = 8))
Col1<-grid.arrange(Chart_1,Table_1,Chart_2,Table_2,ncol=1,nrow=4) %>% annotate_figure(top="Based on daily incidence")
Col2<-grid.arrange(Chart_3,Table_3,Chart_4,Table_4,ncol=1,nrow=4) %>% annotate_figure(top="Based on 3days average daily incidence")
GridPlot<-grid.arrange(Col1,Col2,ncol=2) %>%
ggsave(filename=paste0(folder,"/Output/",CurrentDate,"/InfluenceSmoothing/",Country,"_InfluenceSplineAndTables.jpg"),width = 14, height = 40,limitsize=FALSE)
print(Country)}
#' get_csv function
#' This function will transform any country name as per WHO convention
#' @param dataset - dataset containing country names to convert to WHO reference
#' @param countryfield - name of the field containing country names - Don't use quotes!
#' @export
get_running_csv <- function(){
function(server,service_name,layer_id=0,w="1=1",rg="false",of="*"){
#gets data from an Esri feature service.
#
# args:
#   server (string): name of the arcgis server
#   service_name (string): name of the feature service
#   layer id (int): id of the layer, default = 0
#   w (string): where condition, default = "1=1",
#   rg(string): defines whether geometry is exported. Must be either 'false' or 'true'. Note values must be a string not a boolean
#   of (string): list of output fields. Must be a string not a list or vector. Default is set to export all columns ("*)
#   f (string): output format
#
# returns:
# data (tibble): feature service converted to a tibble
out <- tryCatch(
{
# Get the maximum id. This is need to define the number of calls required to fetch data
res <- content(GET(url = paste(server,service_name,"FeatureServer",layer_id,"query?",sep="/"),
query = list(
where = w,
returnGeometry = rg,
returnIdsOnly = TRUE,
f = "json"),
as = "text", encoding = "UTF-8")) %>%
fromJSON(., flatten = TRUE)
n_records <- res %>% .[2] %>%  as.data.frame(.) %>%#get second list and convert into a data frame
summarise(max_id=max(.[1]), count=n())
id_field <- unlist(res[1])
# Do until all records are exported
# Retrieve recrords from the feature service and merge into a single data frame
id <- 0
data <- tibble()
while (id<n_records$max_id) {
records <- content(GET(url = paste(server,service_name,"FeatureServer",layer_id,"query?",sep="/"),
query = list(
where = paste(w,"and",id_field,">=",id) ,
returnGeometry = rg,
outFields = of,
returnIdsOnly = FALSE,
f = "json")),
as = "text", encoding = "UTF-8") %>%
fromJSON(., flatten = TRUE)  %>% .$features %>% as_tibble() %>%
rename_all(list(~ sub(".*?[[:punct:]]", "",.)))
id_new <- records %>% summarise(max(!!as.name(id_field))) %>% pull
if(nrow(records)==0 | id_new == id ) {
#if no records are returned, break loop
break
} else{
data <- rbind(data,records)
id <- id_new +1
}
}
#convert esri data to dttm
data <- data %>%  mutate_if(~ (is.double(.) && min(., na.rm = TRUE) > 1e12 && min(., na.rm = TRUE) %% 1000 ==0) , list(~as.POSIXct(./1000,origin="1970-01-01",tz="GMT")))
# retrun data
return(data)
},
error = function(cond) {
message(paste0("Request failed. Please review the paramaters."))
#message(request$status_code)
message(cond)
})
}
server <- "https://services.arcgis.com/5T5nSi527N4F7luB/ArcGIS/rest/services"
service_daily <- "EURO_COVID19_Running_v3"
MainDataset<-get_data(server, service_daily)
reurn(MainDataset)}
get_running_csv()
get_running_csv <- function(){
get_data<-function(server,service_name,layer_id=0,w="1=1",rg="false",of="*"){
#gets data from an Esri feature service.
#
# args:
#   server (string): name of the arcgis server
#   service_name (string): name of the feature service
#   layer id (int): id of the layer, default = 0
#   w (string): where condition, default = "1=1",
#   rg(string): defines whether geometry is exported. Must be either 'false' or 'true'. Note values must be a string not a boolean
#   of (string): list of output fields. Must be a string not a list or vector. Default is set to export all columns ("*)
#   f (string): output format
#
# returns:
# data (tibble): feature service converted to a tibble
out <- tryCatch(
{
# Get the maximum id. This is need to define the number of calls required to fetch data
res <- content(GET(url = paste(server,service_name,"FeatureServer",layer_id,"query?",sep="/"),
query = list(
where = w,
returnGeometry = rg,
returnIdsOnly = TRUE,
f = "json"),
as = "text", encoding = "UTF-8")) %>%
fromJSON(., flatten = TRUE)
n_records <- res %>% .[2] %>%  as.data.frame(.) %>%#get second list and convert into a data frame
summarise(max_id=max(.[1]), count=n())
id_field <- unlist(res[1])
# Do until all records are exported
# Retrieve recrords from the feature service and merge into a single data frame
id <- 0
data <- tibble()
while (id<n_records$max_id) {
records <- content(GET(url = paste(server,service_name,"FeatureServer",layer_id,"query?",sep="/"),
query = list(
where = paste(w,"and",id_field,">=",id) ,
returnGeometry = rg,
outFields = of,
returnIdsOnly = FALSE,
f = "json")),
as = "text", encoding = "UTF-8") %>%
fromJSON(., flatten = TRUE)  %>% .$features %>% as_tibble() %>%
rename_all(list(~ sub(".*?[[:punct:]]", "",.)))
id_new <- records %>% summarise(max(!!as.name(id_field))) %>% pull
if(nrow(records)==0 | id_new == id ) {
#if no records are returned, break loop
break
} else{
data <- rbind(data,records)
id <- id_new +1
}
}
#convert esri data to dttm
data <- data %>%  mutate_if(~ (is.double(.) && min(., na.rm = TRUE) > 1e12 && min(., na.rm = TRUE) %% 1000 ==0) , list(~as.POSIXct(./1000,origin="1970-01-01",tz="GMT")))
# retrun data
return(data)
},
error = function(cond) {
message(paste0("Request failed. Please review the paramaters."))
#message(request$status_code)
message(cond)
})
}
server <- "https://services.arcgis.com/5T5nSi527N4F7luB/ArcGIS/rest/services"
service_daily <- "EURO_COVID19_Running_v3"
MainDataset<-get_data(server, service_daily)
reurn(MainDataset)}
#' get_csv function
#' This function will transform any country name as per WHO convention
#' @param dataset - dataset containing country names to convert to WHO reference
#' @param countryfield - name of the field containing country names - Don't use quotes!
#' @export
get_running_csv <- function(){
get_data<-function(server,service_name,layer_id=0,w="1=1",rg="false",of="*"){
#gets data from an Esri feature service.
#
# args:
#   server (string): name of the arcgis server
#   service_name (string): name of the feature service
#   layer id (int): id of the layer, default = 0
#   w (string): where condition, default = "1=1",
#   rg(string): defines whether geometry is exported. Must be either 'false' or 'true'. Note values must be a string not a boolean
#   of (string): list of output fields. Must be a string not a list or vector. Default is set to export all columns ("*)
#   f (string): output format
#
# returns:
# data (tibble): feature service converted to a tibble
out <- tryCatch(
{
# Get the maximum id. This is need to define the number of calls required to fetch data
res <- content(GET(url = paste(server,service_name,"FeatureServer",layer_id,"query?",sep="/"),
query = list(
where = w,
returnGeometry = rg,
returnIdsOnly = TRUE,
f = "json"),
as = "text", encoding = "UTF-8")) %>%
fromJSON(., flatten = TRUE)
n_records <- res %>% .[2] %>%  as.data.frame(.) %>%#get second list and convert into a data frame
summarise(max_id=max(.[1]), count=n())
id_field <- unlist(res[1])
# Do until all records are exported
# Retrieve recrords from the feature service and merge into a single data frame
id <- 0
data <- tibble()
while (id<n_records$max_id) {
records <- content(GET(url = paste(server,service_name,"FeatureServer",layer_id,"query?",sep="/"),
query = list(
where = paste(w,"and",id_field,">=",id) ,
returnGeometry = rg,
outFields = of,
returnIdsOnly = FALSE,
f = "json")),
as = "text", encoding = "UTF-8") %>%
fromJSON(., flatten = TRUE)  %>% .$features %>% as_tibble() %>%
rename_all(list(~ sub(".*?[[:punct:]]", "",.)))
id_new <- records %>% summarise(max(!!as.name(id_field))) %>% pull
if(nrow(records)==0 | id_new == id ) {
#if no records are returned, break loop
break
} else{
data <- rbind(data,records)
id <- id_new +1
}
}
#convert esri data to dttm
data <- data %>%  mutate_if(~ (is.double(.) && min(., na.rm = TRUE) > 1e12 && min(., na.rm = TRUE) %% 1000 ==0) , list(~as.POSIXct(./1000,origin="1970-01-01",tz="GMT")))
# retrun data
return(data)
},
error = function(cond) {
message(paste0("Request failed. Please review the paramaters."))
#message(request$status_code)
message(cond)
})
}
server <- "https://services.arcgis.com/5T5nSi527N4F7luB/ArcGIS/rest/services"
service_daily <- "EURO_COVID19_Running_v3"
MainDataset<-get_data(server, service_daily)
return(MainDataset)}
get_running_csv()
library(dplyr)
get_running_csv()
library(jsonlite)
get_running_csv()
MainDataset<-get_data(server, service_daily)
get_data<-function(server,service_name,layer_id=0,w="1=1",rg="false",of="*"){
#gets data from an Esri feature service.
#
# args:
#   server (string): name of the arcgis server
#   service_name (string): name of the feature service
#   layer id (int): id of the layer, default = 0
#   w (string): where condition, default = "1=1",
#   rg(string): defines whether geometry is exported. Must be either 'false' or 'true'. Note values must be a string not a boolean
#   of (string): list of output fields. Must be a string not a list or vector. Default is set to export all columns ("*)
#   f (string): output format
#
# returns:
# data (tibble): feature service converted to a tibble
out <- tryCatch(
{
# Get the maximum id. This is need to define the number of calls required to fetch data
res <- content(GET(url = paste(server,service_name,"FeatureServer",layer_id,"query?",sep="/"),
query = list(
where = w,
returnGeometry = rg,
returnIdsOnly = TRUE,
f = "json"),
as = "text", encoding = "UTF-8")) %>%
fromJSON(., flatten = TRUE)
n_records <- res %>% .[2] %>%  as.data.frame(.) %>%#get second list and convert into a data frame
summarise(max_id=max(.[1]), count=n())
id_field <- unlist(res[1])
# Do until all records are exported
# Retrieve recrords from the feature service and merge into a single data frame
id <- 0
data <- tibble()
while (id<n_records$max_id) {
records <- content(GET(url = paste(server,service_name,"FeatureServer",layer_id,"query?",sep="/"),
query = list(
where = paste(w,"and",id_field,">=",id) ,
returnGeometry = rg,
outFields = of,
returnIdsOnly = FALSE,
f = "json")),
as = "text", encoding = "UTF-8") %>%
fromJSON(., flatten = TRUE)  %>% .$features %>% as_tibble() %>%
rename_all(list(~ sub(".*?[[:punct:]]", "",.)))
id_new <- records %>% summarise(max(!!as.name(id_field))) %>% pull
if(nrow(records)==0 | id_new == id ) {
#if no records are returned, break loop
break
} else{
data <- rbind(data,records)
id <- id_new +1
}
}
#convert esri data to dttm
data <- data %>%  mutate_if(~ (is.double(.) && min(., na.rm = TRUE) > 1e12 && min(., na.rm = TRUE) %% 1000 ==0) , list(~as.POSIXct(./1000,origin="1970-01-01",tz="GMT")))
# retrun data
return(data)
},
error = function(cond) {
message(paste0("Request failed. Please review the paramaters."))
#message(request$status_code)
message(cond)
})
}
MainDataset<-get_data(server, service_daily)
server <- "https://services.arcgis.com/5T5nSi527N4F7luB/ArcGIS/rest/services"
service_daily <- "EURO_COVID19_Running_v3"
MainDataset<-get_data(server, service_daily)
get_data <- function(server,service_name,layer_id=0,w="1=1",rg="false",of="*"){
#gets data from an Esri feature service.
#
# args:
#   server (string): name of the arcgis server
#   service_name (string): name of the feature service
#   layer id (int): id of the layer, default = 0
#   w (string): where condition, default = "1=1",
#   rg(string): defines whether geometry is exported. Must be either 'false' or 'true'. Note values must be a string not a boolean
#   of (string): list of output fields. Must be a string not a list or vector. Default is set to export all columns ("*)
#   f (string): output format
#
# returns:
# data (tibble): feature service converted to a tibble
out <- tryCatch(
{
# Get the maximum id. This is need to define the number of calls required to fetch data
res <- content(GET(url = paste(server,service_name,"FeatureServer",layer_id,"query?",sep="/"),
query = list(
where = w,
returnGeometry = rg,
returnIdsOnly = TRUE,
f = "json"),
as = "text", encoding = "UTF-8")) %>%
fromJSON(., flatten = TRUE)
n_records <- res %>% .[2] %>%  as.data.frame(.) %>%#get second list and convert into a data frame
summarise(max_id=max(.[1]), count=n())
id_field <- unlist(res[1])
# Do until all records are exported
# Retrieve recrords from the feature service and merge into a single data frame
id <- 0
data <- tibble()
while (id<n_records$max_id) {
records <- content(GET(url = paste(server,service_name,"FeatureServer",layer_id,"query?",sep="/"),
query = list(
where = paste(w,"and",id_field,">=",id) ,
returnGeometry = rg,
outFields = of,
returnIdsOnly = FALSE,
f = "json")),
as = "text", encoding = "UTF-8") %>%
fromJSON(., flatten = TRUE)  %>% .$features %>% as_tibble() %>%
rename_all(list(~ sub(".*?[[:punct:]]", "",.)))
id_new <- records %>% summarise(max(!!as.name(id_field))) %>% pull
if(nrow(records)==0 | id_new == id ) {
#if no records are returned, break loop
break
} else{
data <- rbind(data,records)
id <- id_new +1
}
}
#convert esri data to dttm
data <- data %>%  mutate_if(~ (is.double(.) && min(., na.rm = TRUE) > 1e12 && min(., na.rm = TRUE) %% 1000 ==0) , list(~as.POSIXct(./1000,origin="1970-01-01",tz="GMT")))
# retrun data
return(data)
},
error = function(cond) {
message(paste0("Request failed. Please review the paramaters."))
#message(request$status_code)
message(cond)
})
}
server <- "https://services.arcgis.com/5T5nSi527N4F7luB/ArcGIS/rest/services"
service_daily <- "EURO_COVID19_Running_v3"
MainDataset<-get_data(server, service_daily)
library(httr)
MainDataset<-get_data(server, service_daily)
setwd('C:/Users/romanc/Documents/GitHub/Packages')
library(devtools)
create('get_epi_data')
create('GetEpiData')
use_package('dplyr')
setwd('C:/Users/romanc/Documents/GitHub/Packages/GetEpiData')
use_package('dplyr')
setwd('C:/Users/romanc/Documents/GitHub/Packages/GetEpiData')
use_package('dplyr')
use_package(dplyr)
document()
use_package('dplyr')
document()
use_package('dplyr')
getwd()
