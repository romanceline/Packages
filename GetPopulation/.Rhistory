mutate(Days=as.numeric(Days))
return(CountryDataset)
}
#Prepares the dataset to be smoothened depending on the variable and type of scale
DatasetToSmooth<-function(ctr,CasesOrDeaths,Measure,Log){
CountryDataset<-ResetZero(ctr,Measure)
if(Log=="True"){
if(CasesOrDeaths=="Cases"){
CountryDataset<-CountryDataset %>%
select(ADM0NAME,DateReport1,Days,Variable=log10_MovingAverage_Cases)}
if(CasesOrDeaths=="Deaths"){
CountryDataset<-CountryDataset %>%
select(ADM0NAME,DateReport1,Days,Variable=log10_MovingAverage_Deaths)}}
if(Log=="False"){
if(CasesOrDeaths=="Cases"){
CountryDataset<-CountryDataset %>%
select(ADM0NAME,DateReport1,Days,Variable=ThreeDaysAverage_Cases)}
if(CasesOrDeaths=="Deaths"){
CountryDataset<-CountryDataset %>%
select(ADM0NAME,DateReport1,Days,Variable=ThreeDaysAverage_Deaths)}}
CountryDataset_ <-CountryDataset %>% filter(Variable!=-Inf)
return(CountryDataset_)
}
#Functions calculating spline values
SplineSmooth<-function(ctr,CasesOrDeaths,Measure,par1,Log){
CountryDataset<-DatasetToSmooth(ctr,CasesOrDeaths,Measure,Log) %>% filter(Variable!=-Inf)
SplineFunction<-smooth.spline(x=CountryDataset$Days,y=CountryDataset$Variable,spar=par1)
ValuesSpline<-data.frame(SplineValue=predict(SplineFunction,deriv=0))
CountryDataset<-data.frame(CountryDataset,ValuesSpline) %>% select(-"SplineValue.x","SplineValue"="SplineValue.y")
return(CountryDataset)
}
#Add new column to dataset to spot the date (and so, spline value) of Measure2 (Measure2 means relaxation of measure1)
GlobalCountryDataset<-function(ctr,CasesOrDeaths,Measure,par1,Log){
DatasetToPlot<-DatasetToSmooth(ctr,CasesOrDeaths,Measure,Log) %>%
# left_join((LoessSmooth(ctr,DailyOrMovingAverage,CasesOrDeaths,Measure1,par1,cutDate,Log) %>% select(Days,LoessValue)),by="Days") %>%
left_join((SplineSmooth(ctr,CasesOrDeaths,Measure,par1,Log) %>% select(Days,SplineValue)),by="Days")
DateFirstIntroduction<-DatesByMeasure(ctr,Measure)$DateFirstImplementation
DatesLifting<-DatesByMeasure(ctr,Measure)$DatesLifting
DatesIntroductions<-DateFirstIntroduction<-DatesByMeasure(ctr,Measure)$DateReimplementations
DatasetToPlot<-DatasetToPlot %>% mutate(Reintroduction=if_else(DateReport1 %in% DatesIntroductions,"Yes","No"),
Lifting=if_else(DateReport1 %in% DatesLifting,"Yes","No"))
return(DatasetToPlot)}
DatasetAllCountries<-function(ListCountries,CasesOrDeaths,Measure,par1,Log){
BigDataset<-data.frame()
for (ctry in ListCountries){
CountryDataset<-GlobalCountryDataset(ctry,CasesOrDeaths,Measure,par1,Log)
BigDataset<-bind_rows(CountryDataset,BigDataset)
}
return(BigDataset)
}
# NPIPlot<-function(ListCountries,CasesOrDeaths,Measure,par1,cutDate,Log,RealValues){
#
#   ttl <-case_when(CasesOrDeaths=="Cases" & Log =='True' ~"Daily cases",
#                   CasesOrDeaths=="Cases" & Log =='False' ~"Number of daily COVID-19 Cases",
#                   CasesOrDeaths=='Deaths'& Log =='False'~"Number of daily COVID-19 Deaths",
#                   CasesOrDeaths=='Deaths'& Log =='True'~"Number of daily COVID-19 Deaths (log scale)")
#
#   BigDataset<-DatasetAllCountries(ListCountries,CasesOrDeaths,Measure,par1,Log)
#
#   BigDataset<-BigDataset %>% pivot_longer(cols=c("Variable","SplineValue")) %>%
#     mutate(name = replace(name, name == 'SplineValue', 'Spline approach')) %>%
#     filter(DateReport1<=cutDate)
#
#   BigDataset_Smooth <- BigDataset %>% filter(name == 'Spline approach')
#
#   BigDataset_Values<-BigDataset %>% filter(name == "Variable")
#
#   BigDataset_Reintroduction<- BigDataset_Smooth %>% filter(Reintroduction=="Yes")
#   BigDataset_Lifting<-BigDataset_Smooth %>% filter(Lifting=="Yes")
#
#
#   plot<-ggplot(BigDataset_Smooth)+
#     labs(y=ttl,linetype="Smoothing Approach")+
#     geom_vline(xintercept = 0,linetype="dashed",show.legend = TRUE)+
#     geom_line(aes(x=Days,y=value,group=ADM0NAME,color='First implementation of the \nmeasure at national level'),linetype=2,size=0.75,show.legend=TRUE)+
#     geom_line(aes(x=Days,y=value,group=ADM0NAME,color=ADM0NAME),linetype=1,size=0.75)+
#     scale_x_continuous(breaks=seq(-50,150,50))+theme(legend.title=element_blank(),axis.title.x =element_blank(),legend.text=element_text(size=16))#
#
#   if(Log=="True"){
#     plot<-plot+scale_y_continuous(labels=function(x) round(10^x))}
#
#   if(RealValues=="Yes")
#   {plot<-plot+geom_point(data=BigDataset_Values,aes(x=Days,y=value,color=ADM0NAME),shape=3,alpha=0.5,size=1)}
#
#   if(nrow(BigDataset_Lifting)!=0 & nrow(BigDataset_Reintroduction)==0){
#     plot<-plot+
#       geom_point(data=BigDataset_Lifting,aes(x=Days,y=value,group=ADM0NAME,color="Relaxation of the measure \nat national level"),shape=25,fill='white',size=4,stroke=1,show.legend=TRUE)+
#       #geom_point(data=BigDataset_Lifting,aes(x=Days,y=value,group=ADM0NAME,color=ADM0NAME),shape=21,fill="white",size=5,stroke=1,show.legend=FALSE)+
#       geom_point(data=BigDataset_Lifting,aes(x=Days,y=value,group=ADM0NAME,color=ADM0NAME),shape=25,stroke=1,size=4,show.legend=FALSE)+
#       scale_color_manual(breaks=c(ListCountries,'First implementation of the \nmeasure at national level',"Relaxation of the measure \nat national level"),values=c(MyPalette[1:length(ListCountries)],"black",'black'),guide="legend")+
#       guides(colour=guide_legend(override.aes=list(
#         linetype = c(rep("solid",length(ListCountries)),'dashed','blank'),
#         shape=c(rep(NA,length(ListCountries)),NA,25),
#         size=c(rep(1,length(ListCountries)),0.5,2))))
#   }
#
#   if(nrow(BigDataset_Lifting)==0 & nrow(BigDataset_Reintroduction)==0){
#     plot<-plot+scale_color_manual(breaks=c(ListCountries,'First implementation of the \nmeasure at national level'),values=c(MyPalette[1:length(ListCountries)],"black"),guide="legend")+
#       guides(colour=guide_legend(override.aes=list(
#         linetype = c(rep(length(ListCountries)),'dashed'),
#         shape =c(rep(NA,length(ListCountries)),NA),
#         size=c(rep(1,length(ListCountries)),0.5))))
#   }
#
#
#   if(nrow(BigDataset_Lifting)!=0 & nrow(BigDataset_Reintroduction)!=0){
#     plot<-plot+
#       geom_point(data=BigDataset_Lifting,aes(x=Days,y=value,group=ADM0NAME,color="Relaxation of the measure \nat national level"),shape=25,fill="white",size=4,stroke=1,show.legend=TRUE)+
#       geom_point(data=BigDataset_Lifting,aes(x=Days,y=value,group=ADM0NAME,color=ADM0NAME),shape=25,stroke=1,size=4,show.legend=FALSE)+
#       geom_point(data=BigDataset_Reintroduction,aes(x=Days,y=value,group=ADM0NAME,color="Reintroduction of the \nmeasure at national level"),shape=24,fill="white",size=4,stroke=1,show.legend=TRUE)+
#       geom_point(data=BigDataset_Reintroduction,aes(x=Days,y=value,group=ADM0NAME,color=ADM0NAME),shape=24,stroke=1,size=4,show.legend=FALSE)+
#       scale_color_manual(breaks=c(ListCountries,'First implementation of the \nmeasure at national level',"Relaxation of the measure \nat national level","Reintroduction of the \nmeasure at national level"),values=c(MyPalette[1:length(ListCountries)],"black","black","black"),guide="legend")+
#       guides(colour=guide_legend(override.aes=list(
#         linetype = c(rep("solid",length(ListCountries)),'dashed',"blank","blank"),
#         shape=c(rep(NA,length(ListCountries)),NA,25,24),
#         size=c(rep(1,length(ListCountries)),0.5,2,2))))
#   }
#
#   return(plot)
# }
#Simplified NPI Plot (Keep only date of first implementation, not relaxatiom, second reintroduction,...)
NPIPlot<-function(ListCountries,CasesOrDeaths,Measure,par1,cutDate,Log,RealValues){
ttl <-case_when(CasesOrDeaths=="Cases" & Log =='True' ~"Daily cases",
CasesOrDeaths=="Cases" & Log =='False' ~"Number of daily COVID-19 Cases",
CasesOrDeaths=='Deaths'& Log =='False'~"Number of daily COVID-19 Deaths",
CasesOrDeaths=='Deaths'& Log =='True'~"Number of daily COVID-19 Deaths (log scale)")
BigDataset<-DatasetAllCountries(ListCountries,CasesOrDeaths,Measure,par1,Log)
BigDataset<-BigDataset %>% pivot_longer(cols=c("Variable","SplineValue")) %>%
mutate(name = replace(name, name == 'SplineValue', 'Spline approach')) %>%
filter(DateReport1<=cutDate)
BigDataset_Smooth <- BigDataset %>% filter(name == 'Spline approach')
# BigDataset_Values<-BigDataset %>% filter(name == "Variable")
#
# BigDataset_Reintroduction<- BigDataset_Smooth %>% filter(Reintroduction=="Yes")
# BigDataset_Lifting<-BigDataset_Smooth %>% filter(Lifting=="Yes")
plot<-ggplot(BigDataset_Smooth)+
labs(y=ttl,linetype="Smoothing Approach")+
geom_vline(xintercept = 0,linetype="dashed",show.legend = TRUE)+
geom_line(aes(x=Days,y=value,group=ADM0NAME,color='First implementation of the \nmeasure at national level'),linetype=2,size=0.75,show.legend=TRUE)+
geom_line(aes(x=Days,y=value,group=ADM0NAME,color=ADM0NAME),linetype=1,size=0.75)+
scale_x_continuous(breaks=seq(-50,max(BigDataset_Smooth$Days),50))+
theme(legend.title=element_blank(),axis.title.x =element_blank(),legend.text=element_text(size=16))+
scale_y_continuous(labels=plain)+
scale_color_manual(breaks=c(ListCountries,'First implementation of the \nmeasure at national level'),values=c(MyPalette[1:length(ListCountries)],"black"),guide="legend")+
guides(colour=guide_legend(override.aes=list(
linetype=c(rep('solid',length(ListCountries)),'dashed'))))
if(Log=="True"){
plot<-plot+scale_y_continuous(labels=function(x) round(10^x) %>% plain)}
if(RealValues=="Yes")
{plot<-plot+geom_point(data=BigDataset_Values,aes(x=Days,y=value,color=ADM0NAME),shape=3,alpha=0.5,size=1)}
return(plot)
}
ListCountries_1<-(CountriesPerRegion %>% filter(Region==1))$ADM0NAME
ListCountries_2<-(CountriesPerRegion %>% filter(Region==2))$ADM0NAME
ListCountries_3<-(CountriesPerRegion %>% filter(Region==3))$ADM0NAME
ListCountries_4<-(CountriesPerRegion %>% filter(Region==4))$ADM0NAME
ListCountries_5<-(CountriesPerRegion %>% filter(Region==5))$ADM0NAME
ListCountries_6<-(CountriesPerRegion %>% filter(Region==6))$ADM0NAME
ListCountries_7<-(CountriesPerRegion %>% filter(Region==7))$ADM0NAME
ListCountries_8<-(CountriesPerRegion %>% filter(Region==8))$ADM0NAME
ListCountries_9<-(CountriesPerRegion %>% filter(Region==9))$ADM0NAME
plot1<-NPIPlot(ListCountries_1,'Cases','Any',0.5,CurrentDate,'True','No')
plot2<-NPIPlot(ListCountries_2,'Cases','Any',0.5,CurrentDate,'True','No')
plot3<-NPIPlot(ListCountries_3,'Cases','Any',0.5,CurrentDate,'True','No')
plot4<-NPIPlot(ListCountries_4,'Cases','Any',0.5,CurrentDate,'True','No')
plot5<-NPIPlot(ListCountries_5,'Cases','Any',0.5,CurrentDate,'True','No')
plot6<-NPIPlot(ListCountries_6,'Cases','Any',0.5,CurrentDate,'True','No')
plot7<-NPIPlot(ListCountries_7,'Cases','Any',0.5,CurrentDate,'True','No')
plot8<-NPIPlot(ListCountries_8,'Cases','Any',0.5,CurrentDate,'True','No')
plot9<-NPIPlot(ListCountries_9,'Cases','Any',0.5,CurrentDate,'True','No')
PlotsNPI<-plot_grid(plot1,plot2,plot3,plot4,plot5,plot6,plot7,plot8,plot9,ncol=3,nrow=3)
#### 2.10 Transmission, Hosp and ICU ####
mapICUOcc<-ggdraw() +
draw_image(paste0(folder,"/ForDailyUpdate/maps/EuroICUOccupancy.png"))
mapICUAdm<-ggdraw() +
draw_image(paste0(folder,"/ForDailyUpdate/maps/EuroICUAdmissions.png"))
mapICU<-plot_grid(mapICUOcc,mapICUAdm,nrow=2)
CountriesHospiOver30<-TransmissionIndicators %>%
filter(hosp_rate>=30)
CountriesMortOver5<-TransmissionIndicators %>%
filter(mort_rate>=5) %>% arrange(desc(mort_rate))
CountriesMortOver5_5worst<-CountriesMortOver5 %>% top_n(5,mort_rate)
CountriesCaseIncOver150<-TransmissionIndicators %>%
filter(case_inc>=150)
CountriesPosOver20<-TransmissionIndicators %>%
filter(positivity>=20)
TransmissionBullet1<-paste0(nrow(CountriesHospiOver30),' countries (',
paste(CountriesHospiOver30$WHO_CODE, sep=",", collapse=","),') with hospitalization rate > 30 per 100 000')
TransmissionBullet2<-paste0(nrow(CountriesMortOver5),' countries with mortality rate > 5 per 100 000 (5 most severe: ',
paste(CountriesMortOver5_5worst$WHO_CODE, sep=",", collapse=","),')')
TransmissionBullet3<-paste0(nrow(CountriesCaseIncOver150),' countries with case notification rate > 150 per 100 000')
TransmissionBullet4<-paste0(nrow(CountriesPosOver20),' countries (',
paste(CountriesPosOver20$WHO_CODE, sep=",", collapse=","),') with positivity > 20%')
#### 3 - Generates slide deck ####
render(paste0(folder_,"\\Powerpoint_Creation.Rmd"),output_file=paste0(OutputFolder,"/SlideDeck/","Presentation_",CurrentDate),powerpoint_presentation(reference_doc= "Template.pptx"))
render(paste0(folder_,"\\Powerpoint_Creation.Rmd"),output_file=paste0(OutputFolder,"/SlideDeck/","Presentation_",CurrentDate),powerpoint_presentation(reference_doc= "Template.pptx"))
render(paste0(folder_,"\\Powerpoint_Creation.Rmd"),output_file=paste0(OutputFolder,"/SlideDeck/","Presentation_",CurrentDate),powerpoint_presentation(reference_doc= "Template.pptx"))
render(paste0(folder_,"\\Powerpoint_Creation.Rmd"),output_file=paste0(OutputFolder,"/SlideDeck/","Presentation_",CurrentDate),powerpoint_presentation(reference_doc= "Template.pptx"))
### LOAD PACKAGES
#First time install of the required functions, or update if changed
#devtools::install_github("whocov/phifunc", auth_token = "7fb165f058a1f42c930f75328578253e08028453", subdir = "phifunc", dep = FALSE)
PackagesToInstall<-c('AzureAuth', 'extrafont', 'EpiEstim', 'formattable', 'ggalt', 'ggforce', 'gghighlight', 'hrbrthemes', 'incidence', 'outbreaks', 'sparkline')
for (i in PackagesToInstall) {
print(i)
if (!i %in% installed.packages())
{install.packages(i)}
library(i, character.only = TRUE)
}
library(tidyverse) # general R utilities for data transformation/plotting
library(httr) # for working with APIs
library(jsonlite) #for working with APIs
library(ISOweek) # deals with ISO week formatting
library(phifunc) #  for pulling aggregate data from xMart
library(openxlsx) # creates output in Excel
#-------------------------------------------------------------------------------------------------------
### DEFINE REPORTING WEEK
reporting.week <- str_replace(ISOweek(Sys.Date() - 6), "W", "")
previous.week <- str_replace(ISOweek(Sys.Date() - 13), "W", "")
reporting.week <- "2021-06" #manually enter
previous.week <- "2021-05"
# reporting.week <- str_replace(ISOweek(Sys.Date()), "W", "")
# previous.week <- str_replace(ISOweek(Sys.Date() - 6), "W", "")
#---------------------------------------------------------------------------------------------------------
### PULL IN THE AGGREGATE DATA (VERSION 1 AND COMBINED)
# load the aggregate data from xMart
agg_data1 <- pull_euro_weekly()
#agg_data1 <- read.csv('data_export_NCOV_WEEK_AGG_EURO.csv')
# load the aggregate data from xMart
agg_comb <- pull_euro_weekly_comb() %>%
mutate(report_year=ifelse(report_year==2021 & report_week==53,2020,report_year))
# Line used because transition 2020-2021 messed up (Week 53 for 2021??)
# Check again next week
# merge the data
agg_final <- agg_data1 %>%
filter(!(report_country %in% unique(agg_comb$report_country))) %>%
bind_rows(., agg_comb)
#----------------------------------------------------------------------------------------------------
### DATA MANIPULATION
# filter out age groups
agg_final = agg_final %>%
filter(age_group == "All")
# format week
agg_final = agg_final %>%
mutate(year_week = ifelse(report_week %in% 1:9,
paste0(agg_final$report_year,"-0",agg_final$report_week),
paste0(agg_final$report_year,"-",agg_final$report_week)))
# keep only data from past two weeks
agg_final = agg_final %>%
filter(year_week %in% reporting.week | year_week %in% previous.week)
# keep relevant columns
agg_final = agg_final %>%
select(report_country, year_week, hospitalised, tested_all, ventilated)
# keep only countries with relevant data
agg_final = agg_final %>%
filter(!is.na(hospitalised) | !is.na(tested_all) | !is.na(ventilated))
# group United Kingdom
agg_final = agg_final %>%
mutate(report_country = ifelse(report_country == "United Kingdom, England" |
report_country == "United Kingdom, Northern Ireland" |
report_country == "United Kingdom, Scotland" |
report_country == "Wales",
"United Kingdom",
report_country)) %>%
group_by(report_country, year_week) %>%
summarise(hospitalised = sum(hospitalised),
tested_all = sum(tested_all),
ventilated = sum(ventilated)) %>%
ungroup()
# Take two week average
agg_final = agg_final %>%
group_by(report_country) %>%
summarise(hospitalised = mean(hospitalised),
tested_all = mean(tested_all),
ventilated = mean(ventilated)) %>%
ungroup()
agg_final <- agg_final %>% mutate(report_country=as.character(report_country))
#--------------------------------------------------------------
###  PULL IN THE CASE/DEATH DATA
## CREATE FUNCTION TO PULL DATA
get_data <- function(server,service_name,layer_id=0,w="1=1",rg="false",of="*",maxRecordCount=1000){
#gets data from an Esri feature service.
#
# args:
#   server (string): name of the arcgis server
#   service_name (string): name of the feature service
#   layer id (int): id of the layer, default = 0
#   w (string): where condition, default = "1=1",
#   rg(string): defines whether geometry is exported. Must be either 'false' or 'true'. Note values must be a string not a boolean
#   of (string): list of output fields. Must be a string not a list or vector. Default is set to export all columns ("*)
#   f (string): output format
#   maxRecordCount (int): maximum record count that can be export with a single request. Default is set to 1000
#
# returns:
# data (tibble): feature service converted to a tibble
out <- tryCatch(
{
# Get the maximum id. This is need to define the number of calls required to fetch data
res <- content(GET(url = paste(server,service_name,"FeatureServer",layer_id,"query?",sep="/"),
query = list(
where = w,
returnGeometry = rg,
returnIdsOnly = TRUE,
f = "json"),
as = "text", encoding = "UTF-8")) %>%
fromJSON(., flatten = TRUE)
n_records <- res %>% .[2] %>%  as.data.frame(.) %>%#get second list and convert into a data frame
summarise(max_id=max(.[1]), count=n())
id_field <- unlist(res[1])
# Do until all records are exported
# Retrieve records from the feature service and merge into a single data frame
id <- 0
data <- tibble()
while (id<n_records$max_id) {
records <- content(GET(url = paste(server,service_name,service_type,layer_id,"query?",sep="/"),
query = list(
where = paste(w,"and",id_field,">",id) ,
returnGeometry = rg,
outFields = of,
returnIdsOnly = FALSE,
f = "json")),
as = "text", encoding = "UTF-8") %>%
fromJSON(., flatten = TRUE)  %>% .$features %>% as_tibble() %>%
rename_all(list(~ sub(".*?[[:punct:]]", "",.)))
id_new <- records %>% summarise(max(!!as.name(id_field))) %>% pull
if(nrow(records)==0 | id_new == id ) {
#if no records are returned, break loop
break
} else{
data <- rbind(data,records)
id <- id_new
}
}
#convert esri data to dttm
data <- data %>%  mutate_if(~ (is.double(.) && min(., na.rm = TRUE) > 1e12 && min(., na.rm = TRUE) %% 1000 == 0) , list(~as.POSIXct(./1000,origin="1970-01-01",tz="GMT")))
# retrun data
return(data)
},
error = function(cond) {
message(paste0("Request failed. Please review the paramaters."))
message(request$status_code)
message(cond)
})
}
## LOAD THE POPULATION DATA AND DAILY CASE/DEATH DATA
# Set up function inputs
server <- "https://services.arcgis.com/5T5nSi527N4F7luB/ArcGIS/rest/services"
service_cumul <- "EURO_COVID19_ADM0_Cases"
service_daily <- "EURO_COVID19_Running_v3"
service_type <- "FeatureServer"
country_pop = get_data(server, service_cumul)
View(country_pop)
View(country_pop)
country_pop = get_data(server, 'EURO_COVID_ADM0')
View(country_pop)
get_data <- function(server,service_name,layer_id=0,w="1=1",rg="false",of="*",maxRecordCount=1000){
#gets data from an Esri feature service.
#
# args:
#   server (string): name of the arcgis server
#   service_name (string): name of the feature service
#   layer id (int): id of the layer, default = 0
#   w (string): where condition, default = "1=1",
#   rg(string): defines whether geometry is exported. Must be either 'false' or 'true'. Note values must be a string not a boolean
#   of (string): list of output fields. Must be a string not a list or vector. Default is set to export all columns ("*)
#   f (string): output format
#   maxRecordCount (int): maximum record count that can be export with a single request. Default is set to 1000
#
# returns:
# data (tibble): feature service converted to a tibble
out <- tryCatch(
{
# Get the maximum id. This is need to define the number of calls required to fetch data
res <- content(GET(url = paste(server,service_name,"FeatureServer",layer_id,"query?",sep="/"),
query = list(
where = w,
returnGeometry = rg,
returnIdsOnly = TRUE,
f = "json"),
as = "text", encoding = "UTF-8")) %>%
fromJSON(., flatten = TRUE)
n_records <- res %>% .[2] %>%  as.data.frame(.) %>%#get second list and convert into a data frame
summarise(max_id=max(.[1]), count=n())
id_field <- unlist(res[1])
# Do until all records are exported
# Retrieve records from the feature service and merge into a single data frame
id <- 0
data <- tibble()
while (id<n_records$max_id) {
records <- content(GET(url = paste(server,service_name,service_type,layer_id,"query?",sep="/"),
query = list(
where = paste(w,"and",id_field,">",id) ,
returnGeometry = rg,
outFields = of,
returnIdsOnly = FALSE,
f = "json")),
as = "text", encoding = "UTF-8") %>%
fromJSON(., flatten = TRUE)  %>% .$features %>% as_tibble() %>%
rename_all(list(~ sub(".*?[[:punct:]]", "",.)))
id_new <- records %>% summarise(max(!!as.name(id_field))) %>% pull
if(nrow(records)==0 | id_new == id ) {
#if no records are returned, break loop
break
} else{
data <- rbind(data,records)
id <- id_new
}
}
#convert esri data to dttm
data <- data %>%  mutate_if(~ (is.double(.) && min(., na.rm = TRUE) > 1e12 && min(., na.rm = TRUE) %% 1000 == 0) , list(~as.POSIXct(./1000,origin="1970-01-01",tz="GMT")))
# retrun data
return(data)
},
error = function(cond) {
message(paste0("Request failed. Please review the paramaters."))
message(request$status_code)
message(cond)
})
}
adm_0 <- "EURO_COVID19_ADM0_Cases"
country_pop <- get_data(server, adm_0) %>%
mutate(Population = CENTER_LAT, Country = ADM0_VIZ_N)%>%
mutate(Country = gsub("\\*+","",Country)) %>%
select(WHO_CODE,Country,Population)
View(country_pop)
library('devtools')
setwd('C:/Users/romanc/Documents/GitHub/Packages')
create('GetPopulation')
Get_population<-function(){
get_data <- function(server,service_name,layer_id=0,w="1=1",rg="false",of="*",maxRecordCount=1000){
#gets data from an Esri feature service.
#
# args:
#   server (string): name of the arcgis server
#   service_name (string): name of the feature service
#   layer id (int): id of the layer, default = 0
#   w (string): where condition, default = "1=1",
#   rg(string): defines whether geometry is exported. Must be either 'false' or 'true'. Note values must be a string not a boolean
#   of (string): list of output fields. Must be a string not a list or vector. Default is set to export all columns ("*)
#   f (string): output format
#   maxRecordCount (int): maximum record count that can be export with a single request. Default is set to 1000
#
# returns:
# data (tibble): feature service converted to a tibble
out <- tryCatch(
{
# Get the maximum id. This is need to define the number of calls required to fetch data
res <- content(GET(url = paste(server,service_name,"FeatureServer",layer_id,"query?",sep="/"),
query = list(
where = w,
returnGeometry = rg,
returnIdsOnly = TRUE,
f = "json"),
as = "text", encoding = "UTF-8")) %>%
fromJSON(., flatten = TRUE)
n_records <- res %>% .[2] %>%  as.data.frame(.) %>%#get second list and convert into a data frame
summarise(max_id=max(.[1]), count=n())
id_field <- unlist(res[1])
# Do until all records are exported
# Retrieve records from the feature service and merge into a single data frame
id <- 0
data <- tibble()
while (id<n_records$max_id) {
records <- content(GET(url = paste(server,service_name,service_type,layer_id,"query?",sep="/"),
query = list(
where = paste(w,"and",id_field,">",id) ,
returnGeometry = rg,
outFields = of,
returnIdsOnly = FALSE,
f = "json")),
as = "text", encoding = "UTF-8") %>%
fromJSON(., flatten = TRUE)  %>% .$features %>% as_tibble() %>%
rename_all(list(~ sub(".*?[[:punct:]]", "",.)))
id_new <- records %>% summarise(max(!!as.name(id_field))) %>% pull
if(nrow(records)==0 | id_new == id ) {
#if no records are returned, break loop
break
} else{
data <- rbind(data,records)
id <- id_new
}
}
#convert esri data to dttm
data <- data %>%  mutate_if(~ (is.double(.) && min(., na.rm = TRUE) > 1e12 && min(., na.rm = TRUE) %% 1000 == 0) , list(~as.POSIXct(./1000,origin="1970-01-01",tz="GMT")))
# retrun data
return(data)
},
error = function(cond) {
message(paste0("Request failed. Please review the paramaters."))
message(request$status_code)
message(cond)
})
}
server <- "https://services.arcgis.com/5T5nSi527N4F7luB/ArcGIS/rest/services"
adm_0 <- "EURO_COVID19_ADM0_Cases"
country_pop <- get_data(server, adm_0) %>%
mutate(Population = CENTER_LAT, Country = ADM0_VIZ_N)%>%
mutate(Country = gsub("\\*+","",Country)) %>%
select(WHO_CODE,Country,Population)
return(country_pop)
}
Get_population()
use_package('httr',type='Depends')
setwd('C:/Users/romanc/Documents/GitHub/Packages/GetPopulation')
use_package('httr',type='Depends')
getwd()
use_package('httr',type='depends')
document()
use_package('httr',type='depends')
use_package('httr',type='Depends')
document()
use_package('httr',type='Depends')
getwd()
